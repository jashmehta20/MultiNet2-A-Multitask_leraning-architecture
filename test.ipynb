{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class RandomScaleCrop(object):\n",
    "    def __init__(self, scale=[1.0, 1.2, 1.5]):\n",
    "        self.scale = scale\n",
    "\n",
    "    def __call__(self, img, label, depth, normal):\n",
    "        height, width = img.shape[-2:]\n",
    "        sc = self.scale[random.randint(0, len(self.scale) - 1)]\n",
    "        h, w = int(height / sc), int(width / sc)\n",
    "        i = random.randint(0, height - h)\n",
    "        j = random.randint(0, width - w)\n",
    "        img_ = F.interpolate(img[None, :, i:i + h, j:j + w], size=(height, width), mode='bilinear', align_corners=True).squeeze(0)\n",
    "        label_ = F.interpolate(label[None, None, i:i + h, j:j + w], size=(height, width), mode='nearest').squeeze(0).squeeze(0)\n",
    "        depth_ = F.interpolate(depth[None, :, i:i + h, j:j + w], size=(height, width), mode='nearest').squeeze(0)\n",
    "        normal_ = F.interpolate(normal[None, :, i:i + h, j:j + w], size=(height, width), mode='bilinear', align_corners=True).squeeze(0)\n",
    "        return img_, label_, depth_ / sc, normal_\n",
    "\n",
    "\n",
    "class NYUv2(Dataset):\n",
    "    \"\"\"\n",
    "    We could further improve the performance with the data augmentation of NYUv2 defined in:\n",
    "        [1] PAD-Net: Multi-Tasks Guided Prediction-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing\n",
    "        [2] Pattern affinitive propagation across depth, surface normal and semantic segmentation\n",
    "        [3] Mti-net: Multiscale task interaction networks for multi-task learning\n",
    "\n",
    "        1. Random scale in a selected raio 1.0, 1.2, and 1.5.\n",
    "        2. Random horizontal flip.\n",
    "\n",
    "    Please note that: all baselines and MTAN did NOT apply data augmentation in the original paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, train=True, augmentation=False):\n",
    "        self.train = train\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "        # read the data file\n",
    "        if train:\n",
    "            self.data_path = root + '/train'\n",
    "        else:\n",
    "            self.data_path = root + '/val'\n",
    "\n",
    "        # calculate data length\n",
    "        self.data_len = len(fnmatch.filter(os.listdir(self.data_path + '/image'), '*.npy'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load data from the pre-processed npy files\n",
    "        image = torch.from_numpy(np.moveaxis(np.load(self.data_path + '/image/{:d}.npy'.format(index)), -1, 0))\n",
    "        semantic = torch.from_numpy(np.load(self.data_path + '/label/{:d}.npy'.format(index)))\n",
    "        depth = torch.from_numpy(np.moveaxis(np.load(self.data_path + '/depth/{:d}.npy'.format(index)), -1, 0))\n",
    "        normal = torch.from_numpy(np.moveaxis(np.load(self.data_path + '/normal/{:d}.npy'.format(index)), -1, 0))\n",
    "\n",
    "        # apply data augmentation if required\n",
    "        if self.augmentation:\n",
    "            image, semantic, depth, normal = RandomScaleCrop()(image, semantic, depth, normal)\n",
    "            if torch.rand(1) < 0.5:\n",
    "                image = torch.flip(image, dims=[2])\n",
    "                semantic = torch.flip(semantic, dims=[1])\n",
    "                depth = torch.flip(depth, dims=[2])\n",
    "                normal = torch.flip(normal, dims=[2])\n",
    "                normal[0, :, :] = - normal[0, :, :]\n",
    "\n",
    "        return image.float(), semantic.float(), depth.float(), normal.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ds = NYUv2(root=r\"C:\\Users\\neetm\\Desktop\\DL\\mtan\\nyu\\nyuv2\", train=False)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segnet2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Segnet2, self).__init__()\n",
    "        self._encoder = models.vgg16(pretrained=True).features\n",
    "        self.upsample = nn.ConvTranspose2d(in_channels=512, out_channels=256, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Define task metrics, loss functions and model trainer here.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def model_fit(x_pred, x_output, task_type):\n",
    "    device = x_pred.device\n",
    "\n",
    "    # binary mark to mask out undefined pixel space\n",
    "    binary_mask = (torch.sum(x_output, dim=1) != 0).float().unsqueeze(1).to(device)\n",
    "\n",
    "    if task_type == 'semantic':\n",
    "        # semantic loss: depth-wise cross entropy\n",
    "        loss = F.nll_loss(x_pred, x_output, ignore_index=-1)\n",
    "\n",
    "    if task_type == 'depth':\n",
    "        # depth loss: l1 norm\n",
    "        loss = torch.sum(torch.abs(x_pred - x_output) * binary_mask) / torch.nonzero(binary_mask, as_tuple=False).size(0)\n",
    "\n",
    "    if task_type == 'normal':\n",
    "        # normal loss: dot product\n",
    "        loss = 1 - torch.sum((x_pred * x_output) * binary_mask) / torch.nonzero(binary_mask, as_tuple=False).size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "class ConfMatrix(object):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.mat = None\n",
    "\n",
    "    def update(self, pred, target):\n",
    "        n = self.num_classes\n",
    "        if self.mat is None:\n",
    "            self.mat = torch.zeros((n, n), dtype=torch.int64, device=pred.device)\n",
    "        with torch.no_grad():\n",
    "            k = (target >= 0) & (target < n)\n",
    "            inds = n * target[k].to(torch.int64) + pred[k]\n",
    "            self.mat += torch.bincount(inds, minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        h = self.mat.float()\n",
    "        acc = torch.diag(h).sum() / h.sum()\n",
    "        iu = torch.diag(h) / (h.sum(1) + h.sum(0) - torch.diag(h))\n",
    "        return torch.mean(iu).item(), acc.item()\n",
    "\n",
    "\n",
    "def depth_error(x_pred, x_output):\n",
    "    device = x_pred.device\n",
    "    binary_mask = (torch.sum(x_output, dim=1) != 0).unsqueeze(1).to(device)\n",
    "    x_pred_true = x_pred.masked_select(binary_mask)\n",
    "    x_output_true = x_output.masked_select(binary_mask)\n",
    "    abs_err = torch.abs(x_pred_true - x_output_true)\n",
    "    rel_err = torch.abs(x_pred_true - x_output_true) / x_output_true\n",
    "    return (torch.sum(abs_err) / torch.nonzero(binary_mask, as_tuple=False).size(0)).item(), \\\n",
    "           (torch.sum(rel_err) / torch.nonzero(binary_mask, as_tuple=False).size(0)).item()\n",
    "\n",
    "\n",
    "def normal_error(x_pred, x_output):\n",
    "    binary_mask = (torch.sum(x_output, dim=1) != 0)\n",
    "    error = torch.acos(torch.clamp(torch.sum(x_pred * x_output, 1).masked_select(binary_mask), -1, 1)).detach().cpu().numpy()\n",
    "    error = np.degrees(error)\n",
    "    return np.mean(error), np.median(error), np.mean(error < 11.25), np.mean(error < 22.5), np.mean(error < 30)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "=========== Universal Multi-task Trainer =========== \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def multi_task_trainer(train_loader, test_loader, multi_task_model, device, optimizer, scheduler, opt, total_epoch=200):\n",
    "    train_batch = len(train_loader)\n",
    "    test_batch = len(test_loader)\n",
    "    T = opt.temp\n",
    "    avg_cost = np.zeros([total_epoch, 24], dtype=np.float32)\n",
    "    lambda_weight = np.ones([3, total_epoch])\n",
    "    for index in range(total_epoch):\n",
    "        cost = np.zeros(24, dtype=np.float32)\n",
    "\n",
    "        # apply Dynamic Weight Average\n",
    "        if opt.weight == 'dwa':\n",
    "            if index == 0 or index == 1:\n",
    "                lambda_weight[:, index] = 1.0\n",
    "            else:\n",
    "                w_1 = avg_cost[index - 1, 0] / avg_cost[index - 2, 0]\n",
    "                w_2 = avg_cost[index - 1, 3] / avg_cost[index - 2, 3]\n",
    "                w_3 = avg_cost[index - 1, 6] / avg_cost[index - 2, 6]\n",
    "                lambda_weight[0, index] = 3 * np.exp(w_1 / T) / (np.exp(w_1 / T) + np.exp(w_2 / T) + np.exp(w_3 / T))\n",
    "                lambda_weight[1, index] = 3 * np.exp(w_2 / T) / (np.exp(w_1 / T) + np.exp(w_2 / T) + np.exp(w_3 / T))\n",
    "                lambda_weight[2, index] = 3 * np.exp(w_3 / T) / (np.exp(w_1 / T) + np.exp(w_2 / T) + np.exp(w_3 / T))\n",
    "\n",
    "        # iteration for all batches\n",
    "        multi_task_model.train()\n",
    "        train_dataset = iter(train_loader)\n",
    "        conf_mat = ConfMatrix(13)\n",
    "        for k in range(train_batch):\n",
    "            train_data, train_label, train_depth, train_normal = train_dataset.next()\n",
    "            train_data, train_label = train_data.to(device), train_label.long().to(device)\n",
    "            train_depth, train_normal = train_depth.to(device), train_normal.to(device)\n",
    "\n",
    "            train_pred, logsigma = multi_task_model(train_data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss = [model_fit(train_pred[0], train_label, 'semantic'),\n",
    "                          model_fit(train_pred[1], train_depth, 'depth'),\n",
    "                          model_fit(train_pred[2], train_normal, 'normal')]\n",
    "\n",
    "            if opt.weight == 'equal' or opt.weight == 'dwa':\n",
    "                loss = sum([lambda_weight[i, index] * train_loss[i] for i in range(3)])\n",
    "            else:\n",
    "                loss = sum(1 / (2 * torch.exp(logsigma[i])) * train_loss[i] + logsigma[i] / 2 for i in range(3))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # accumulate label prediction for every pixel in training images\n",
    "            conf_mat.update(train_pred[0].argmax(1).flatten(), train_label.flatten())\n",
    "\n",
    "            cost[0] = train_loss[0].item()\n",
    "            cost[3] = train_loss[1].item()\n",
    "            cost[4], cost[5] = depth_error(train_pred[1], train_depth)\n",
    "            cost[6] = train_loss[2].item()\n",
    "            cost[7], cost[8], cost[9], cost[10], cost[11] = normal_error(train_pred[2], train_normal)\n",
    "            avg_cost[index, :12] += cost[:12] / train_batch\n",
    "\n",
    "        # compute mIoU and acc\n",
    "        avg_cost[index, 1:3] = np.array(conf_mat.get_metrics())\n",
    "\n",
    "        # evaluating test data\n",
    "        multi_task_model.eval()\n",
    "        conf_mat = ConfMatrix(13)\n",
    "        with torch.no_grad():  # operations inside don't track history\n",
    "            test_dataset = iter(test_loader)\n",
    "            for k in range(test_batch):\n",
    "                test_data, test_label, test_depth, test_normal = test_dataset.next()\n",
    "                test_data, test_label = test_data.to(device), test_label.long().to(device)\n",
    "                test_depth, test_normal = test_depth.to(device), test_normal.to(device)\n",
    "\n",
    "                test_pred, _ = multi_task_model(test_data)\n",
    "                test_loss = [model_fit(test_pred[0], test_label, 'semantic'),\n",
    "                             model_fit(test_pred[1], test_depth, 'depth'),\n",
    "                             model_fit(test_pred[2], test_normal, 'normal')]\n",
    "\n",
    "                conf_mat.update(test_pred[0].argmax(1).flatten(), test_label.flatten())\n",
    "\n",
    "                cost[12] = test_loss[0].item()\n",
    "                cost[15] = test_loss[1].item()\n",
    "                cost[16], cost[17] = depth_error(test_pred[1], test_depth)\n",
    "                cost[18] = test_loss[2].item()\n",
    "                cost[19], cost[20], cost[21], cost[22], cost[23] = normal_error(test_pred[2], test_normal)\n",
    "                avg_cost[index, 12:] += cost[12:] / test_batch\n",
    "\n",
    "            # compute mIoU and acc\n",
    "            avg_cost[index, 13:15] = np.array(conf_mat.get_metrics())\n",
    "\n",
    "        scheduler.step()\n",
    "        print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} ||'\n",
    "            'TEST: {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} '\n",
    "            .format(index, avg_cost[index, 0], avg_cost[index, 1], avg_cost[index, 2], avg_cost[index, 3],\n",
    "                    avg_cost[index, 4], avg_cost[index, 5], avg_cost[index, 6], avg_cost[index, 7], avg_cost[index, 8],\n",
    "                    avg_cost[index, 9], avg_cost[index, 10], avg_cost[index, 11], avg_cost[index, 12], avg_cost[index, 13],\n",
    "                    avg_cost[index, 14], avg_cost[index, 15], avg_cost[index, 16], avg_cost[index, 17], avg_cost[index, 18],\n",
    "                    avg_cost[index, 19], avg_cost[index, 20], avg_cost[index, 21], avg_cost[index, 22], avg_cost[index, 23]))\n",
    "\n",
    "        if index%5==0:\n",
    "            state_dict = {\"model_state_dict\":multi_task_model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict(), \"epoch\": index, \"loss\": avg_cost}\n",
    "            torch.save(state_dict, os.path.join(opt.ckpt_dir, f\"model_epoch_{index}.pth\"))\n",
    "\"\"\"\n",
    "=========== Universal Single-task Trainer =========== \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def single_task_trainer(train_loader, test_loader, single_task_model, device, optimizer, scheduler, task, ckpt_dir, total_epoch=200):\n",
    "    train_batch = len(train_loader)\n",
    "    test_batch = len(test_loader)\n",
    "    avg_cost = np.zeros([total_epoch, 24], dtype=np.float32)\n",
    "    for index in range(total_epoch):\n",
    "        cost = np.zeros(24, dtype=np.float32)\n",
    "\n",
    "        # iteration for all batches\n",
    "        single_task_model.train()\n",
    "        train_dataset = iter(train_loader)\n",
    "        conf_mat = ConfMatrix(13)\n",
    "        for k in range(train_batch):\n",
    "            train_data, train_label, train_depth, train_normal = train_dataset.next()\n",
    "            train_data, train_label = train_data.to(device), train_label.long().to(device)\n",
    "            train_depth, train_normal = train_depth.to(device), train_normal.to(device)\n",
    "\n",
    "            train_pred = single_task_model(train_data)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if task == 'semantic':\n",
    "                train_loss = model_fit(train_pred, train_label, task)\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                conf_mat.update(train_pred.argmax(1).flatten(), train_label.flatten())\n",
    "                cost[0] = train_loss.item()\n",
    "\n",
    "            if task == 'depth':\n",
    "                train_loss = model_fit(train_pred, train_depth, task)\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                cost[3] = train_loss.item()\n",
    "                cost[4], cost[5] = depth_error(train_pred, train_depth)\n",
    "\n",
    "            if task == 'normal':\n",
    "                train_loss = model_fit(train_pred, train_normal, task)\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                cost[6] = train_loss.item()\n",
    "                cost[7], cost[8], cost[9], cost[10], cost[11] = normal_error(train_pred, train_normal)\n",
    "\n",
    "            avg_cost[index, :12] += cost[:12] / train_batch\n",
    "\n",
    "        if task == 'semantic':\n",
    "            avg_cost[index, 1:3] = np.array(conf_mat.get_metrics())\n",
    "\n",
    "        # evaluating test data\n",
    "        single_task_model.eval()\n",
    "        conf_mat = ConfMatrix(13)\n",
    "        with torch.no_grad():  # operations inside don't track history\n",
    "            test_dataset = iter(test_loader)\n",
    "            for k in range(test_batch):\n",
    "                test_data, test_label, test_depth, test_normal = test_dataset.next()\n",
    "                test_data, test_label = test_data.to(device),  test_label.long().to(device)\n",
    "                test_depth, test_normal = test_depth.to(device), test_normal.to(device)\n",
    "\n",
    "                test_pred = single_task_model(test_data)\n",
    "\n",
    "                if task == 'semantic':\n",
    "                    test_loss = model_fit(test_pred, test_label, task)\n",
    "\n",
    "                    conf_mat.update(test_pred.argmax(1).flatten(), test_label.flatten())\n",
    "                    cost[12] = test_loss.item()\n",
    "\n",
    "                if task == 'depth':\n",
    "                    test_loss = model_fit(test_pred, test_depth, task)\n",
    "                    cost[15] = test_loss.item()\n",
    "                    cost[16], cost[17] = depth_error(test_pred, test_depth)\n",
    "\n",
    "                if task == 'normal':\n",
    "                    test_loss = model_fit(test_pred, test_normal, task)\n",
    "                    cost[18] = test_loss.item()\n",
    "                    cost[19], cost[20], cost[21], cost[22], cost[23] = normal_error(test_pred, test_normal)\n",
    "\n",
    "                avg_cost[index, 12:] += cost[12:] / test_batch\n",
    "            if task == 'semantic':\n",
    "                avg_cost[index, 13:15] = np.array(conf_mat.get_metrics())\n",
    "\n",
    "        scheduler.step()\n",
    "        if task == 'semantic':\n",
    "            print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} TEST: {:.4f} {:.4f} {:.4f}'\n",
    "              .format(index, avg_cost[index, 0], avg_cost[index, 1], avg_cost[index, 2], avg_cost[index, 12], avg_cost[index, 13], avg_cost[index, 14]))\n",
    "        if task == 'depth':\n",
    "            print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} TEST: {:.4f} {:.4f} {:.4f}'\n",
    "              .format(index, avg_cost[index, 3], avg_cost[index, 4], avg_cost[index, 5], avg_cost[index, 15], avg_cost[index, 16], avg_cost[index, 17]))\n",
    "        if task == 'normal':\n",
    "            print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} TEST: {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'\n",
    "              .format(index, avg_cost[index, 6], avg_cost[index, 7], avg_cost[index, 8], avg_cost[index, 9], avg_cost[index, 10], avg_cost[index, 11],\n",
    "                      avg_cost[index, 18], avg_cost[index, 19], avg_cost[index, 20], avg_cost[index, 21], avg_cost[index, 22], avg_cost[index, 23]))\n",
    "\n",
    "        \n",
    "        if index%5==0:\n",
    "            state_dict = {\"model_state_dict\":single_task_model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict(), \"epoch\": index, \"loss\": avg_cost}\n",
    "            torch.save(state_dict, os.path.join(ckpt_dir, f\"model_epoch_{index}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super().__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "\n",
    "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
    "        for idx in range(len(self.ranges)):\n",
    "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\"%(idx+1)] = x\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class FCN8s(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
    "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
    "        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
    "\n",
    "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
    "        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)\n",
    "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
    "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
    "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
    "        score = self.classifier(score) \n",
    "        score = F.log_softmax(score, dim=1)                   # size=(N, n_class, x.H/1, x.W/1)\n",
    "\n",
    "        return score  # size=(N, n_class, x.H/1, x.W/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGNet()\n",
    "model2 = FCN8s(model, 13).cuda()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = optim.Adam(model2.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "nyuv2_test_set = NYUv2(root=r\"C:\\Users\\neetm\\Desktop\\DL\\mtan\\nyu\\nyuv2\", train=False)\n",
    "nyuv2_train_set = NYUv2(root=r\"C:\\Users\\neetm\\Desktop\\DL\\mtan\\nyu\\nyuv2\", train=True, augmentation=True)\n",
    "batch_size = 4\n",
    "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=nyuv2_train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=nyuv2_test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_task_trainer(nyuv2_train_loader,\n",
    "                    nyuv2_test_loader,\n",
    "                    model2,\n",
    "                    device,\n",
    "                    optimizer,\n",
    "                    scheduler,\n",
    "                    'semantic',\n",
    "                    r\"C:\\Users\\neetm\\Desktop\\DL\\MultiNet2-A-Multitask_leraning-architecture\\ckpt_dir\",\n",
    "                    200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\neetm/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [02:02<00:00, 1.99MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.alexnet(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bab824e8d19437ce96ef49137ad111fd75814e22f621ddffdfca7ac1872dc735"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
